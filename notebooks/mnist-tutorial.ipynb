{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based off of [What is torch.nn really?](https://pytorch.org/tutorials/beginner/nn_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection, preprocessing\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label,pixel0,pixel1,pixel2,pixel3,pixel4,pixel5,pixel6,pixel7,pixel8,pixel9,pixel10,pixel11,pixel12,pixel13,pixel14,pixel15,pixel16,pixel17,pixel18,pixel19,pixel20,pixel21,pixel22,pixel23,pixel24,pixel25,pixel26,pixel27,pixel28,pixel29,pixel30,pixel31,pixel32,pixel33,pixel34,pixel35,pixel36,pixel37,pixel38,pixel39,pixel40,pixel41,pixel42,pixel43,pixel44,pixel45,pixel46,pixel47,pixel48,pixel49,pixel50,pixel51,pixel52,pixel53,pixel54,pixel55,pixel56,pixel57,pixel58,pixel59,pixel60,pixel61,pixel62,pixel63,pixel64,pixel65,pixel66,pixel67,pixel68,pixel69,pixel70,pixel71,pixel72,pixel73,pixel74,pixel75,pixel76,pixel77,pixel78,pixel79,pixel80,pixel81,pixel82,pixel83,pixel84,pixel85,pixel86,pixel87,pixel88,pixel89,pixel90,pixel91,pixel92,pixel93,pixel94,pixel95,pixel96,pixel97,pixel98,pixel99,pixel100,pixel101,pixel102,pixel103,pixel104,pixel105,pixel106,pixel107,pixel108,pixel109,pixel110,pixel111,pixel112,pixel113,pixel114,pixel115,pixel116,pixel117,pixel118,pixel119,pixel120,pixel121,pixel122,pixel123,pixel124,pixel125,pixel126,pixel127,pixel128,pixel129,pixel130,pixel131,pixel132,pixel133,pixel134,pixel135,pixel136,pixel137,pixel138,pixel139,pixel140,pixel141,pixel142,pixel143,pixel144,pixel145,pixel146,pixel147,pixel148,pixel149,pixel150,pixel151,pixel152,pixel153,pixel154,pixel155,pixel156,pixel157,pixel158,pixel159,pixel160,pixel161,pixel162,pixel163,pixel164,pixel165,pixel166,pixel167,pixel168,pixel169,pixel170,pixel171,pixel172,pixel173,pixel174,pixel175,pixel176,pixel177,pixel178,pixel179,pixel180,pixel181,pixel182,pixel183,pixel184,pixel185,pixel186,pixel187,pixel188,pixel189,pixel190,pixel191,pixel192,pixel193,pixel194,pixel195,pixel196,pixel197,pixel198,pixel199,pixel200,pixel201,pixel202,pixel203,pixel204,pixel205,pixel206,pixel207,pixel208,pixel209,pixel210,pixel211,pixel212,pixel213,pixel214,pixel215,pixel216,pixel217,pixel218,pixel219,pixel220,pixel221,pixel222,pixel223,pixel224,pixel225,pixel226,pixel227,pixel228,pixel229,pixel230,pixel231,pixel232,pixel233,pixel234,pixel235,pixel236,pixel237,pixel238,pixel239,pixel240,pixel241,pixel242,pixel243,pixel244,pixel245,pixel246,pixel247,pixel248,pixel249,pixel250,pixel251,pixel252,pixel253,pixel254,pixel255,pixel256,pixel257,pixel258,pixel259,pixel260,pixel261,pixel262,pixel263,pixel264,pixel265,pixel266,pixel267,pixel268,pixel269,pixel270,pixel271,pixel272,pixel273,pixel274,pixel275,pixel276,pixel277,pixel278,pixel279,pixel280,pixel281,pixel282,pixel283,pixel284,pixel285,pixel286,pixel287,pixel288,pixel289,pixel290,pixel291,pixel292,pixel293,pixel294,pixel295,pixel296,pixel297,pixel298,pixel299,pixel300,pixel301,pixel302,pixel303,pixel304,pixel305,pixel306,pixel307,pixel308,pixel309,pixel310,pixel311,pixel312,pixel313,pixel314,pixel315,pixel316,pixel317,pixel318,pixel319,pixel320,pixel321,pixel322,pixel323,pixel324,pixel325,pixel326,pixel327,pixel328,pixel329,pixel330,pixel331,pixel332,pixel333,pixel334,pixel335,pixel336,pixel337,pixel338,pixel339,pixel340,pixel341,pixel342,pixel343,pixel344,pixel345,pixel346,pixel347,pixel348,pixel349,pixel350,pixel351,pixel352,pixel353,pixel354,pixel355,pixel356,pixel357,pixel358,pixel359,pixel360,pixel361,pixel362,pixel363,pixel364,pixel365,pixel366,pixel367,pixel368,pixel369,pixel370,pixel371,pixel372,pixel373,pixel374,pixel375,pixel376,pixel377,pixel378,pixel379,pixel380,pixel381,pixel382,pixel383,pixel384,pixel385,pixel386,pixel387,pixel388,pixel389,pixel390,pixel391,pixel392,pixel393,pixel394,pixel395,pixel396,pixel397,pixel398,pixel399,pixel400,pixel401,pixel402,pixel403,pixel404,pixel405,pixel406,pixel407,pixel408,pixel409,pixel410,pixel411,pixel412,pixel413,pixel414,pixel415,pixel416,pixel417,pixel418,pixel419,pixel420,pixel421,pixel422,pixel423,pixel424,pixel425,pixel426,pixel427,pixel428,pixel429,pixel430,pixel431,pixel432,pixel433,pixel434,pixel435,pixel436,pixel437,pixel438,pixel439,pixel440,pixel441,pixel442,pixel443,pixel444,pixel445,pixel446,pixel447,pixel448,pixel449,pixel450,pixel451,pixel452,pixel453,pixel454,pixel455,pixel456,pixel457,pixel458,pixel459,pixel460,pixel461,pixel462,pixel463,pixel464,pixel465,pixel466,pixel467,pixel468,pixel469,pixel470,pixel471,pixel472,pixel473,pixel474,pixel475,pixel476,pixel477,pixel478,pixel479,pixel480,pixel481,pixel482,pixel483,pixel484,pixel485,pixel486,pixel487,pixel488,pixel489,pixel490,pixel491,pixel492,pixel493,pixel494,pixel495,pixel496,pixel497,pixel498,pixel499,pixel500,pixel501,pixel502,pixel503,pixel504,pixel505,pixel506,pixel507,pixel508,pixel509,pixel510,pixel511,pixel512,pixel513,pixel514,pixel515,pixel516,pixel517,pixel518,pixel519,pixel520,pixel521,pixel522,pixel523,pixel524,pixel525,pixel526,pixel527,pixel528,pixel529,pixel530,pixel531,pixel532,pixel533,pixel534,pixel535,pixel536,pixel537,pixel538,pixel539,pixel540,pixel541,pixel542,pixel543,pixel544,pixel545,pixel546,pixel547,pixel548,pixel549,pixel550,pixel551,pixel552,pixel553,pixel554,pixel555,pixel556,pixel557,pixel558,pixel559,pixel560,pixel561,pixel562,pixel563,pixel564,pixel565,pixel566,pixel567,pixel568,pixel569,pixel570,pixel571,pixel572,pixel573,pixel574,pixel575,pixel576,pixel577,pixel578,pixel579,pixel580,pixel581,pixel582,pixel583,pixel584,pixel585,pixel586,pixel587,pixel588,pixel589,pixel590,pixel591,pixel592,pixel593,pixel594,pixel595,pixel596,pixel597,pixel598,pixel599,pixel600,pixel601,pixel602,pixel603,pixel604,pixel605,pixel606,pixel607,pixel608,pixel609,pixel610,pixel611,pixel612,pixel613,pixel614,pixel615,pixel616,pixel617,pixel618,pixel619,pixel620,pixel621,pixel622,pixel623,pixel624,pixel625,pixel626,pixel627,pixel628,pixel629,pixel630,pixel631,pixel632,pixel633,pixel634,pixel635,pixel636,pixel637,pixel638,pixel639,pixel640,pixel641,pixel642,pixel643,pixel644,pixel645,pixel646,pixel647,pixel648,pixel649,pixel650,pixel651,pixel652,pixel653,pixel654,pixel655,pixel656,pixel657,pixel658,pixel659,pixel660,pixel661,pixel662,pixel663,pixel664,pixel665,pixel666,pixel667,pixel668,pixel669,pixel670,pixel671,pixel672,pixel673,pixel674,pixel675,pixel676,pixel677,pixel678,pixel679,pixel680,pixel681,pixel682,pixel683,pixel684,pixel685,pixel686,pixel687,pixel688,pixel689,pixel690,pixel691,pixel692,pixel693,pixel694,pixel695,pixel696,pixel697,pixel698,pixel699,pixel700,pixel701,pixel702,pixel703,pixel704,pixel705,pixel706,pixel707,pixel708,pixel709,pixel710,pixel711,pixel712,pixel713,pixel714,pixel715,pixel716,pixel717,pixel718,pixel719,pixel720,pixel721,pixel722,pixel723,pixel724,pixel725,pixel726,pixel727,pixel728,pixel729,pixel730,pixel731,pixel732,pixel733,pixel734,pixel735,pixel736,pixel737,pixel738,pixel739,pixel740,pixel741,pixel742,pixel743,pixel744,pixel745,pixel746,pixel747,pixel748,pixel749,pixel750,pixel751,pixel752,pixel753,pixel754,pixel755,pixel756,pixel757,pixel758,pixel759,pixel760,pixel761,pixel762,pixel763,pixel764,pixel765,pixel766,pixel767,pixel768,pixel769,pixel770,pixel771,pixel772,pixel773,pixel774,pixel775,pixel776,pixel777,pixel778,pixel779,pixel780,pixel781,pixel782,pixel783\r",
      "\r\n",
      "1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,188,255,94,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,250,253,93,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,123,248,253,167,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,80,247,253,208,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,29,207,253,235,77,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,54,209,253,253,88,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,93,254,253,238,170,17,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,210,254,253,159,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,209,253,254,240,81,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,27,253,253,254,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,206,254,254,198,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,168,253,253,196,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,203,253,248,76,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,188,253,245,93,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,103,253,253,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,240,253,195,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,220,253,253,80,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,94,253,253,253,94,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,251,253,250,131,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,214,218,95,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\r",
      "\r\n",
      "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,30,137,137,192,86,72,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,86,250,254,254,254,254,217,246,151,32,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,179,254,254,254,254,254,254,254,254,254,231,54,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,72,254,254,254,254,254,254,254,254,254,254,254,254,104,0,0,0,0,0,0,0,0,0,0,0,0,0,61,191,254,254,254,254,254,109,83,199,254,254,254,254,243,85,0,0,0,0,0,0,0,0,0,0,0,0,172,254,254,254,202,147,147,45,0,11,29,200,254,254,254,171,0,0,0,0,0,0,0,0,0,0,0,1,174,254,254,89,67,0,0,0,0,0,0,128,252,254,254,212,76,0,0,0,0,0,0,0,0,0,0,47,254,254,254,29,0,0,0,0,0,0,0,0,83,254,254,254,153,0,0,0,0,0,0,0,0,0,0,80,254,254,240,24,0,0,0,0,0,0,0,0,25,240,254,254,153,0,0,0,0,0,0,0,0,0,0,64,254,254,186,7,0,0,0,0,0,0,0,0,0,166,254,254,224,12,0,0,0,0,0,0,0,0,14,232,254,254,254,29,0,0,0,0,0,0,0,0,0,75,254,254,254,17,0,0,0,0,0,0,0,0,18,254,254,254,254,29,0,0,0,0,0,0,0,0,0,48,254,254,254,17,0,0,0,0,0,0,0,0,2,163,254,254,254,29,0,0,0,0,0,0,0,0,0,48,254,254,254,17,0,0,0,0,0,0,0,0,0,94,254,254,254,200,12,0,0,0,0,0,0,0,16,209,254,254,150,1,0,0,0,0,0,0,0,0,0,15,206,254,254,254,202,66,0,0,0,0,0,21,161,254,254,245,31,0,0,0,0,0,0,0,0,0,0,0,60,212,254,254,254,194,48,48,34,41,48,209,254,254,254,171,0,0,0,0,0,0,0,0,0,0,0,0,0,86,243,254,254,254,254,254,233,243,254,254,254,254,254,86,0,0,0,0,0,0,0,0,0,0,0,0,0,0,114,254,254,254,254,254,254,254,254,254,254,239,86,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,182,254,254,254,254,254,254,254,254,243,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,76,146,254,255,254,255,146,19,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\r",
      "\r\n",
      "1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,141,139,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,254,254,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,254,254,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,254,254,106,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,254,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,254,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,254,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,185,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,146,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,254,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,254,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,254,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,254,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,254,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,156,254,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,185,255,255,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,185,254,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,185,254,254,184,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,63,254,254,62,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\r",
      "\r\n",
      "4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,220,179,6,0,0,0,0,0,0,0,0,9,77,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,247,17,0,0,0,0,0,0,0,0,27,202,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,242,155,0,0,0,0,0,0,0,0,27,254,63,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,160,207,6,0,0,0,0,0,0,0,27,254,65,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,127,254,21,0,0,0,0,0,0,0,20,239,65,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,77,254,21,0,0,0,0,0,0,0,0,195,65,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,70,254,21,0,0,0,0,0,0,0,0,195,142,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,56,251,21,0,0,0,0,0,0,0,0,195,227,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,222,153,5,0,0,0,0,0,0,0,120,240,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,67,251,40,0,0,0,0,0,0,0,94,255,69,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,234,184,0,0,0,0,0,0,0,19,245,69,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,234,169,0,0,0,0,0,0,0,3,199,182,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,154,205,4,0,0,26,72,128,203,208,254,254,131,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,61,254,129,113,186,245,251,189,75,56,136,254,73,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,216,233,233,159,104,52,0,0,0,38,254,73,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,254,73,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,254,73,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,206,106,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,186,159,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,209,101,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\r",
      "\r\n",
      "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,25,130,155,254,254,254,157,30,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,103,253,253,253,253,253,253,253,253,114,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,208,253,253,253,253,253,253,253,253,253,253,107,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,253,253,253,253,253,253,253,253,253,253,253,215,101,3,0,0,0,0,0,0,0,0,0,0,0,0,23,210,253,253,253,248,161,222,222,246,253,253,253,253,253,39,0,0,0,0,0,0,0,0,0,0,0,0,136,253,253,253,229,77,0,0,0,70,218,253,253,253,253,215,91,0,0,0,0,0,0,0,0,0,0,5,214,253,253,253,195,0,0,0,0,0,104,224,253,253,253,253,215,29,0,0,0,0,0,0,0,0,0,116,253,253,253,247,75,0,0,0,0,0,0,26,200,253,253,253,253,216,4,0,0,0,0,0,0,0,0,254,253,253,253,195,0,0,0,0,0,0,0,0,26,200,253,253,253,253,5,0,0,0,0,0,0,0,0,254,253,253,253,99,0,0,0,0,0,0,0,0,0,25,231,253,253,253,36,0,0,0,0,0,0,0,0,254,253,253,253,99,0,0,0,0,0,0,0,0,0,0,223,253,253,253,129,0,0,0,0,0,0,0,0,254,253,253,253,99,0,0,0,0,0,0,0,0,0,0,127,253,253,253,129,0,0,0,0,0,0,0,0,254,253,253,253,99,0,0,0,0,0,0,0,0,0,0,139,253,253,253,90,0,0,0,0,0,0,0,0,254,253,253,253,99,0,0,0,0,0,0,0,0,0,78,248,253,253,253,5,0,0,0,0,0,0,0,0,254,253,253,253,216,34,0,0,0,0,0,0,0,33,152,253,253,253,107,1,0,0,0,0,0,0,0,0,206,253,253,253,253,140,0,0,0,0,0,30,139,234,253,253,253,154,2,0,0,0,0,0,0,0,0,0,16,205,253,253,253,250,208,106,106,106,200,237,253,253,253,253,209,22,0,0,0,0,0,0,0,0,0,0,0,82,253,253,253,253,253,253,253,253,253,253,253,253,253,209,22,0,0,0,0,0,0,0,0,0,0,0,0,1,91,253,253,253,253,253,253,253,253,253,253,213,90,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,18,129,208,253,253,253,253,159,129,90,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\r",
      "\r\n",
      "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,141,202,254,193,44,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,165,254,179,163,249,244,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,135,254,150,0,0,189,254,243,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,82,248,209,5,0,0,164,236,254,115,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,211,254,58,0,0,0,0,33,230,212,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,119,254,156,3,0,0,0,0,18,230,254,33,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,212,254,35,0,0,0,0,0,33,254,254,33,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,116,254,154,3,0,0,0,0,0,33,254,254,33,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,124,254,115,0,0,0,0,0,0,160,254,239,23,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,203,254,35,0,0,0,0,0,0,197,254,178,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,239,221,11,0,0,0,0,0,0,198,255,123,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,238,178,0,0,0,0,0,0,10,219,254,96,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,30,249,204,0,0,0,0,0,0,25,235,254,62,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,243,204,0,0,0,0,0,0,91,254,248,36,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,33,254,204,0,0,0,0,0,67,241,254,133,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,33,254,214,7,0,0,0,50,242,254,194,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,193,254,78,0,0,19,128,254,195,36,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,103,254,222,74,143,235,254,228,83,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,30,242,254,254,254,254,252,84,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,64,158,200,174,61,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\r",
      "\r\n",
      "7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,82,152,71,51,51,21,41,51,51,51,51,113,193,152,30,0,0,0,0,0,0,0,0,0,0,0,0,0,122,253,252,253,252,223,243,253,252,253,252,253,252,233,30,0,0,0,0,0,0,0,0,0,0,0,0,0,123,102,41,102,102,102,102,102,102,102,162,254,253,142,0,0,0,0,0,0,0,0,0,0,0,0,0,0,203,102,0,0,0,0,0,0,0,0,183,253,212,20,0,0,0,0,0,0,0,0,0,0,0,0,0,0,203,142,0,0,0,0,0,0,0,11,213,254,91,0,0,0,0,0,0,0,0,0,0,0,0,0,0,41,243,102,0,0,0,0,0,0,0,51,252,172,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,41,223,102,0,0,0,0,0,0,0,214,253,102,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,20,0,0,0,0,0,0,0,253,252,102,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,62,254,253,41,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,102,253,171,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,163,254,91,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,203,253,50,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,51,253,254,50,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,51,252,253,50,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,51,253,254,50,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,51,252,213,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,152,253,82,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,233,252,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,255,253,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,253,212,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\r",
      "\r\n",
      "3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,130,190,254,254,250,175,135,96,96,16,4,0,0,0,0,0,0,0,0,0,0,0,0,0,26,102,186,254,254,248,222,222,225,254,254,254,254,254,206,112,4,0,0,0,0,0,0,0,0,0,0,0,207,254,254,177,117,39,0,0,56,248,102,48,48,103,192,254,135,0,0,0,0,0,0,0,0,0,0,0,91,111,36,0,0,0,0,0,72,92,0,0,0,0,12,224,210,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,50,139,240,254,66,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,121,220,254,244,194,15,0,0,0,0,0,0,0,0,0,0,0,0,0,8,107,112,112,112,87,112,141,218,248,177,68,20,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,77,221,254,254,254,254,254,225,104,39,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,32,32,32,32,130,215,195,47,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,111,231,174,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,47,18,0,0,0,0,0,0,0,0,0,40,228,205,35,0,0,0,0,0,0,0,0,0,0,0,0,22,234,42,0,0,0,0,0,0,0,0,0,0,56,212,226,38,0,0,0,0,0,0,0,0,0,0,0,96,157,0,0,0,0,0,0,0,0,0,0,0,0,30,215,188,9,0,0,0,0,0,0,0,0,0,0,96,142,0,0,0,0,0,0,0,0,0,0,0,0,0,86,254,68,0,0,0,0,0,0,0,0,0,0,71,202,15,0,0,0,0,0,0,0,0,0,0,0,0,6,214,151,0,0,0,0,0,0,0,0,0,0,10,231,86,2,0,0,0,0,0,0,0,0,0,0,0,0,191,207,0,0,0,0,0,0,0,0,0,0,0,93,248,129,7,0,0,0,0,0,0,0,0,0,0,117,238,112,0,0,0,0,0,0,0,0,0,0,0,0,94,248,209,73,12,0,0,0,0,0,0,42,147,252,136,9,0,0,0,0,0,0,0,0,0,0,0,0,0,48,160,215,230,158,74,64,94,153,223,250,214,105,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,129,189,234,224,255,194,134,75,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\r",
      "\r\n",
      "5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,41,149,156,179,254,254,201,119,46,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,147,241,253,253,254,253,253,253,253,245,160,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,224,253,253,180,174,175,174,174,174,174,223,247,145,6,0,0,0,0,0,0,0,0,0,0,0,0,7,197,254,253,165,2,0,0,0,0,0,0,12,102,184,16,0,0,0,0,0,0,0,0,0,0,0,0,152,253,254,162,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,235,254,158,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,74,250,253,15,0,0,0,16,20,19,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,199,253,253,0,0,25,130,235,254,247,145,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,253,253,177,100,219,240,253,253,254,253,253,125,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,193,253,253,254,253,253,200,155,155,238,253,229,23,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,61,249,254,241,150,30,0,0,0,215,254,254,58,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,36,39,30,0,0,0,0,0,214,253,234,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,41,241,253,183,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,201,253,253,102,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,114,254,253,154,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,62,254,255,241,30,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,118,235,253,249,103,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,81,0,102,211,253,253,253,135,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,79,243,234,254,253,253,216,117,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,48,245,253,254,207,126,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head ../data/raw/mnist/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_arr = np.loadtxt(\"../data/raw/mnist/train.csv\", delimiter=',', skiprows=1, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw features are between 0 and 255\n",
    "mnist_arr.min(), mnist_arr.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the MNIST data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prng = np.random.RandomState(42)\n",
    "training_arr, validation_arr = model_selection.train_test_split(mnist_arr, test_size=0.20, random_state=prng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33600, 785)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_target, training_features = training_arr[:, 0], training_arr[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8400, 785)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_target, validation_features = validation_arr[:, 0], validation_arr[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to rescale the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pughdr/.conda/envs/pytorch-gpu-tutorial/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/pughdr/.conda/envs/pytorch-gpu-tutorial/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaled_training_features = min_max_scaler.fit_transform(training_features)\n",
    "scaled_validation_features = min_max_scaler.fit_transform(validation_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out a training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, ax = plt.subplots(1,1)\n",
    "_ = ax.imshow(scaled_training_features[0].reshape((28, 28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch uses `torch.tensor` rather than `numpy.ndarray` so we need to convert data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_target = torch.tensor(training_target)\n",
    "scaled_training_features = torch.tensor(scaled_training_features, dtype=torch.float32)\n",
    "\n",
    "validation_target = torch.tensor(validation_target)\n",
    "scaled_validation_features = torch.tensor(scaled_validation_features, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_training_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_training_features.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_training_features.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 5, 3,  ..., 2, 6, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_samples, number_features = scaled_training_features.shape\n",
    "\n",
    "# using Xavier initialization (divide weights by sqrt(number_features))\n",
    "weights = torch.randn(number_features, 10) / math.sqrt(number_features)\n",
    "weights.requires_grad_() # trailing underscore indicates in-place operation\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _linear_transformation(X):\n",
    "    return X @ weights + bias\n",
    "\n",
    "def _log_softmax_activation(X):\n",
    "    return X - X.exp().sum(-1).log().unsqueeze(-1)\n",
    "    \n",
    "def model(X):\n",
    "    Z = _linear_transformation(X)\n",
    "    return _log_softmax_activation(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "output = model(scaled_training_features[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.6039, -2.7502, -2.4771, -2.2918, -1.7146, -2.5615, -2.3451, -2.0644,\n",
       "        -2.1464, -2.5234], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood(output, target):\n",
    "    m, _ = output.shape\n",
    "    return -output[range(m), target].mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3410, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_log_likelihood(output, training_target[:batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    predictions = torch.argmax(output, dim=1)\n",
    "    return (predictions == target).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0938)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(output, training_target[:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_epochs = 2\n",
    "number_batches = (number_samples - 1) // batch_size + 1\n",
    "\n",
    "learning_rate = 0.5\n",
    "for epoch in range(number_epochs):\n",
    "    for batch in range(number_batches):\n",
    "        # forward pass\n",
    "        start = batch * batch_size\n",
    "        X = scaled_training_features[start:(start + batch_size)]\n",
    "        y = training_target[start:(start + batch_size)]\n",
    "        output = model(X)\n",
    "        loss = negative_log_likelihood(output, y)\n",
    "        \n",
    "        # back propagation\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= learning_rate * weights.grad\n",
    "            bias -= learning_rate * bias.grad\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0933, grad_fn=<NegBackward>), tensor(0.9844))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_log_likelihood(model(X), y), accuracy(model(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor using `torch.nn.functional`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X):\n",
    "    return X @ weights + bias\n",
    "\n",
    "loss_function = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0933, grad_fn=<NllLossBackward>), tensor(0.9844))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(model(X), y), accuracy(model(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor using `torch.nn.Module`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class MNISTLogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784))\n",
    "        self._bias = nn.Parameter(torch.zeros(10))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X @ self._weights + self._bias\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3830, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(model(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, loss_function, number_samples, number_epochs=2, batch_size=64):\n",
    "    \n",
    "    number_batches = (number_samples - 1) // batch_size + 1\n",
    "    for epoch in range(number_epochs):\n",
    "        for batch in range(number_batches):\n",
    "            # forward pass\n",
    "            start = batch * batch_size\n",
    "            X = scaled_training_features[start:(start + batch_size)]\n",
    "            y = training_target[start:(start + batch_size)]\n",
    "            output = model(X)\n",
    "            loss = loss_function(output, y)\n",
    "\n",
    "            # back propagation\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for parameter in model.parameters():\n",
    "                    parameter -= learning_rate * parameter.grad\n",
    "                model.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, loss_function, number_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0937, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(model(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactoring using `nn.Linear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class MNISTLogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._linear_layer = nn.Linear(784, 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self._linear_layer(X)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2898, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(model(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, loss_function, number_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0923, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(model(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactoring using `torch.optim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, loss_function, optimizer, number_samples, number_epochs=2, batch_size=64):\n",
    "    \n",
    "    number_batches = (number_samples - 1) // batch_size + 1\n",
    "    for epoch in range(number_epochs):\n",
    "        for batch in range(number_batches):\n",
    "            # forward pass\n",
    "            start = batch * batch_size\n",
    "            X = scaled_training_features[start:(start + batch_size)]\n",
    "            y = training_target[start:(start + batch_size)]\n",
    "            output = model(X)\n",
    "            loss = loss_function(output, y)\n",
    "            \n",
    "            # back propagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, F.cross_entropy, optim.SGD(model.parameters(), lr=0.5), number_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0815, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(model(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor using `TensorDataSet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data.TensorDataset(scaled_training_features, training_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, loss_function, optimizer, number_samples, number_epochs=2, batch_size=64):\n",
    "    \n",
    "    number_batches = (number_samples - 1) // batch_size + 1\n",
    "    for epoch in range(number_epochs):\n",
    "        for batch in range(number_batches):\n",
    "            # forward pass\n",
    "            start = batch * batch_size\n",
    "            X, y = training_data[start:(start + batch_size)]\n",
    "            output = model(X)\n",
    "            loss = loss_function(output, y)\n",
    "            \n",
    "            # back propagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, F.cross_entropy, optim.SGD(model.parameters(), lr=0.5), number_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0763, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(model(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor using `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_loader = data.DataLoader(training_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, loss_function, optimizer, data_loader, number_epochs=2):\n",
    "    \n",
    "    for epoch in range(number_epochs):\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            loss = loss_function(output, y)\n",
    "            \n",
    "            # back propagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, F.cross_entropy, optim.SGD(model.parameters(), lr=0.5), training_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1167, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(model(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = data.TensorDataset(scaled_validation_features, validation_target)\n",
    "validation_data_loader = data.DataLoader(validation_data, batch_size=2*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, loss_function, optimizer, training_data_loader, validation_data_loader=None, number_epochs=2):\n",
    "    \n",
    "    for epoch in range(number_epochs):\n",
    "        model.train()\n",
    "        for X, y in training_data_loader:\n",
    "            output = model(X)\n",
    "            loss = loss_function(output, y)\n",
    "            \n",
    "            # back propagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # compute validation loss after each training epoch\n",
    "        if validation_data_loader is not None:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                batch_losses, batch_sizes = zip(*[(loss_function(model(X), y), len(X)) for X, y in validation_data_loader])\n",
    "                validation_loss = np.sum(np.multiply(batch_losses, batch_sizes)) / np.sum(batch_sizes)\n",
    "            print(epoch, validation_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3094427846726917\n",
      "1 0.29399465594972884\n"
     ]
    }
   ],
   "source": [
    "fit(model, F.cross_entropy, optim.SGD(model.parameters(), lr=0.5), training_data_loader, validation_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switching to CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self._conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self._conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = X.view(-1, 1, 28, 28) # implicit knowledge of MNIST data shape!\n",
    "        X = F.relu(self._conv1(X))\n",
    "        X = F.relu(self._conv2(X))\n",
    "        X = F.relu(self._conv3(X))\n",
    "        X = F.avg_pool2d(X, 4)\n",
    "        return X.view(-1, X.size(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5103448293322609\n",
      "1 0.35839658135459534\n"
     ]
    }
   ],
   "source": [
    "model = MNISTCNN()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "fit(model, F.cross_entropy, optimizer, training_data_loader, validation_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor using `nn.Sequential`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, f):\n",
    "        super().__init__()\n",
    "        self._f = f\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self._f(X)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    LambdaLayer(lambda X: X.view(-1, 1, 28, 28)),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    LambdaLayer(lambda X: X.view(X.size(0), -1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5062314249220349\n",
      "1 0.3074838808604649\n"
     ]
    }
   ],
   "source": [
    "fit(model,\n",
    "    F.cross_entropy,\n",
    "    optim.SGD(model.parameters(), lr=0.1, momentum=0.9),\n",
    "    training_data_loader,\n",
    "    validation_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    \n",
    "    def __init__(self, data_loader, f):\n",
    "        self._data_loader = data_loader\n",
    "        self._f = f\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._data_loader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in iter(self._data_loader):\n",
    "            yield self._f(*batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = lambda X, y: (X.view(-1, 1, 28, 28), y)\n",
    "training_data_loader = WrappedDataLoader(training_data_loader, preprocess)\n",
    "validation_data_loader = WrappedDataLoader(validation_data_loader, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    LambdaLayer(lambda X: X.view(X.size(0), -1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5092156639553251\n",
      "1 0.2856105839638483\n"
     ]
    }
   ],
   "source": [
    "fit(model,\n",
    "    F.cross_entropy,\n",
    "    optim.SGD(model.parameters(), lr=0.1, momentum=0.9),\n",
    "    training_data_loader,\n",
    "    validation_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = lambda X, y: (X.view(-1, 1, 28, 28).to(\"cuda\"), y.to(\"cuda\"))\n",
    "training_data_loader = WrappedDataLoader(training_data_loader, preprocess)\n",
    "validation_data_loader = WrappedDataLoader(validation_data_loader, preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.2705, device='cuda:0')\n",
      "1 tensor(0.2642, device='cuda:0')\n",
      "2 tensor(0.2062, device='cuda:0')\n",
      "3 tensor(0.2148, device='cuda:0')\n",
      "4 tensor(0.2027, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "fit(model.to(\"cuda\"),\n",
    "    F.cross_entropy,\n",
    "    optim.SGD(model.parameters(), lr=0.1, momentum=0.9),\n",
    "    training_data_loader,\n",
    "    validation_data_loader,\n",
    "    number_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submitting to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-train the model using the entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pughdr/.conda/envs/pytorch-gpu-tutorial/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "training_target, training_features = mnist_arr[:, 0], mnist_arr[:, 1:]\n",
    "scaled_training_features = min_max_scaler.fit_transform(training_features)\n",
    "scaled_training_features_tensor = torch.tensor(scaled_training_features, dtype=torch.float32)\n",
    "training_target_tensor = torch.tensor(training_target)\n",
    "\n",
    "training_data = data.TensorDataset(scaled_training_features_tensor, training_target_tensor)\n",
    "training_data_loader = data.DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "wrapped_training_data_loader = WrappedDataLoader(training_data_loader, preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model.to(\"cuda\"),\n",
    "    F.cross_entropy,\n",
    "    optim.SGD(model.parameters(), lr=0.1, momentum=0.9),\n",
    "    wrapped_training_data_loader,\n",
    "    number_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageId,Label\r",
      "\r\n",
      "1,0\r",
      "\r\n",
      "2,0\r",
      "\r\n",
      "3,0\r",
      "\r\n",
      "4,0\r",
      "\r\n",
      "5,0\r",
      "\r\n",
      "6,0\r",
      "\r\n",
      "7,0\r",
      "\r\n",
      "8,0\r",
      "\r\n",
      "9,0\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# submission format for kaggle\n",
    "!head ../data/raw/mnist/sample_submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use trained model to make predictions using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_features = np.loadtxt(\"../data/raw/mnist/test.csv\", delimiter=',', skiprows=1, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pughdr/.conda/envs/pytorch-gpu-tutorial/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaled_testing_features = min_max_scaler.fit_transform(testing_features)\n",
    "scaled_testing_features = torch.tensor(scaled_testing_features, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(scaled_testing_features.view(-1, 1, 28, 28).to(\"cuda\"))\n",
    "predictions = torch.argmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_predictions, = predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "df = pd.DataFrame({\"ImageId\": range(1, number_predictions + 1), \"Label\": predictions.cpu()})\n",
    "df.to_csv(f\"../data/kaggle-submissions/mnist/submission-{timestamp}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 208k/208k [00:04<00:00, 51.3kB/s]\n",
      "Successfully submitted to Digit Recognizer"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit digit-recognizer -f ../data/kaggle-submissions/mnist/submission-20190203-145624.csv -m \"My first ever Kaggle submission!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
